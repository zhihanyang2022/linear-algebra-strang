{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1758c7dd-e86f-44b6-9fe1-f3fb5edf79bf",
   "metadata": {},
   "source": [
    "# Reverse-mode automatic differentiation\n",
    "\n",
    "March 13, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "119fca02-f92e-49a5-bbf9-42b6f9de7064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97442248-762a-43e4-bdb4-ed27c3ff86a4",
   "metadata": {},
   "source": [
    "## Functions and their vJP/pullback rules (rrules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f91a2b-685b-4fcb-8eb7-0544982d9a1b",
   "metadata": {},
   "source": [
    "From Nocedal and Wright (slightly modified):\n",
    "\n",
    "> Whenever an elementary operation is performed, we can form and store a new node containing the intermediate result, pointers to this new node from parents, and the partial derivatives associated with these arcs.\n",
    "\n",
    "This implementation idea works when all nodes store scalars, but fails when nodes may store vectors and matrices. This is because chain rule for vectors and matrices are more complicated - they are sometimes referred to as *pullback rules* / *reverse-mode rules* (rrules).\n",
    "\n",
    "My implementation makes two changes to this:\n",
    "- Instead of storing a reference to children, we use closure to save children. (Idea from Julia)\n",
    "- Store pullback rules\n",
    "\n",
    "Many pullback rules can be found here: https://www.youtube.com/playlist?list=PLISXH-iEM4Jn3SEi07q8MJmDD6BaMWlJE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "976520ef-80cf-4209-a648-5050c030679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.pullback_fns = []\n",
    "        self.cotangent = np.zeros(value.shape)\n",
    "        self.finalized = False\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return len(self.value.shape)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(self.value)\n",
    "\n",
    "    def pullback(self):\n",
    "        assert not self.finalized\n",
    "        for pullback_fn in self.pullback_fns:\n",
    "            self.cotangent += pullback_fn()\n",
    "        self.finalized = True\n",
    "\n",
    "    def __add__(x, y):\n",
    "        if x.dim == 0 and y.dim == 0:  # scalar addition\n",
    "            z = Tensor(x.value + y.value)\n",
    "            x.pullback_fns.append(lambda: z.cotangent)\n",
    "            y.pullback_fns.append(lambda: z.cotangent)\n",
    "        elif x.dim == 2 and y.dim == 1:  # matrix-vector addition (involving broadcasting)\n",
    "            z = Tensor(x.value + y.value.reshape(1, -1))\n",
    "            x.pullback_fns.append(lambda: z.cotangent)\n",
    "            y.pullback_fns.append(lambda: z.cotangent.sum(0))\n",
    "        else:  \n",
    "            raise TypeError()\n",
    "        return z\n",
    "\n",
    "    def __mul__(x, y):\n",
    "        if x.dim == 0 and y.dim == 0:  # scalar multiplication\n",
    "            z = Tensor(x.value * y.value)\n",
    "            x.pullback_fns.append(lambda: z.cotangent * y.value)\n",
    "            y.pullback_fns.append(lambda: z.cotangent * x.value)\n",
    "        else:\n",
    "            raise TypeError()\n",
    "        return z\n",
    "\n",
    "    def __matmul__(x, y):\n",
    "        if x.dim == 2 and y.dim == 2:  # matrix multiplication\n",
    "            z = Tensor(x.value @ y.value)\n",
    "            x.pullback_fns.append(lambda: z.cotangent @ y.value.T)\n",
    "            y.pullback_fns.append(lambda: x.value.T @ z.cotangent)\n",
    "        else:\n",
    "            raise TypeError\n",
    "        return z\n",
    "    \n",
    "    def __truediv__(x, y):\n",
    "        if x.dim == 0 and y.dim == 0:  # scalar division\n",
    "            z = Tensor(x.value / y.value)\n",
    "            x.pullback_fns.append(lambda: z.cotangent * (1 / y.value))\n",
    "            y.pullback_fns.append(lambda: z.cotangent * - x.value / (y.value ** 2))\n",
    "        else:\n",
    "            raise TypeError()\n",
    "        return z\n",
    "\n",
    "\n",
    "def exp(x):  # elementwise exp\n",
    "    z = Tensor(np.exp(x.value))\n",
    "    x.pullback_fns.append(lambda: z.cotangent * z.value)\n",
    "    return z\n",
    "\n",
    "\n",
    "def sin(x):  # elementwise sine\n",
    "    z = Tensor(np.sin(x.value))\n",
    "    x.pullback_fns.append(lambda: z.cotangent * np.cos(x.value))\n",
    "    return z\n",
    "\n",
    "\n",
    "def relu(x):  # elementwise relu\n",
    "    z = Tensor(x.value * (x.value > 0))\n",
    "    x.pullback_fns.append(lambda: z.cotangent * (x.value > 0))\n",
    "    return z\n",
    "    \n",
    "\n",
    "def mse(x, target):\n",
    "    if x.dim == 2 and target.dim == 2:\n",
    "        diff = x.value - target.value\n",
    "        z = Tensor(np.mean(diff ** 2))\n",
    "        x.pullback_fns.append(lambda: z.cotangent * 2 / x.value.size * diff)\n",
    "        target.pullback_fns.append(lambda: z.cotangent * - 2 / x.value.size * diff)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6d25bd-4be2-47f4-997b-a1818d930a4c",
   "metadata": {},
   "source": [
    "## Computation graph with scalars only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45959b18-df94-4d20-bdba-d355103f3c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.681277\n",
      "5.3406386\n",
      "-3.8052409\n"
     ]
    }
   ],
   "source": [
    "x1 = Tensor(np.array(1.))\n",
    "x2 = Tensor(np.array(2.))\n",
    "x3 = Tensor(np.array(np.pi/2))\n",
    "\n",
    "x4 = x1 * x2\n",
    "x5 = sin(x3)\n",
    "x6 = exp(x4)\n",
    "x7 = x4 * x5\n",
    "x8 = x6 + x7\n",
    "x9 = x8 / x3\n",
    "x10 = x8 / x2\n",
    "\n",
    "# use 0 and 1 to get the cotangent from x10\n",
    "x9.cotangent = np.array(1.)\n",
    "x10.cotangent = np.array(0.)\n",
    "tape = [x1, x2, x3, x4, x5, x6, x7, x8, x9, x10]\n",
    "\n",
    "for tensor in tape[::-1]: \n",
    "    tensor.pullback()\n",
    "\n",
    "print(x1.cotangent)\n",
    "print(x2.cotangent)\n",
    "print(x3.cotangent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa69114d-b62f-4a9c-81ac-5c82c6e5cdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    x1, x2, x3 = x\n",
    "    x4 = x1 * x2\n",
    "    x5 = np.sin(x3)\n",
    "    x6 = np.exp(x4)\n",
    "    x7 = x4 * x5\n",
    "    x8 = x6 + x7\n",
    "    x9 = x8 / x3\n",
    "    x10 = x8 / x2\n",
    "    return np.array([x9, x10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "830b6f37-b98e-435c-8405-be8ea209367c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([5.9772587, 4.694528 ], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(np.array([1., 2., np.pi/2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec286d8-bb1c-491e-b2fd-08d693ba7499",
   "metadata": {},
   "source": [
    "### Compare against JAX's autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5fbe34c5-9885-4dda-9f3f-bf6b5a84c518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.0681277e+01,  5.3406386e+00, -3.8052409e+00],\n",
       "       [ 8.3890562e+00,  1.8472641e+00, -4.3711388e-08]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.jacrev(func)(np.array([1., 2., np.pi/2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af777d01-ca13-4a5f-93f0-c20f622c6a31",
   "metadata": {},
   "source": [
    "## Computation graph with matrices and vectors (a MLP regression model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50c6a4c0-4bab-43f9-b1c6-725d15b03027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_init(num_input_features, num_output_features, seed):\n",
    "    # kaiming normal init, used to ensure similar variance in inputted and outputted data of each layer\n",
    "    W = jax.random.normal(seed, shape=(num_input_features, num_output_features)) / math.sqrt(num_input_features)\n",
    "    b = np.zeros(num_output_features)\n",
    "    return Tensor(W), Tensor(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aaa4a73f-b5bc-4e24-bfd0-8896c07f6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "x = np.linspace(-1, 1, num=100)\n",
    "y = np.linspace(-1, 1, num=100)\n",
    "xs, ys = np.meshgrid(x, y)\n",
    "zs = (xs ** 3 - ys ** 2)\n",
    "xs_f, ys_f, zs_f = xs.flatten(), ys.flatten(), zs.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3251eb3c-95c4-4d3c-96e1-bee6ef912405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.4287767, dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computation graph\n",
    "\n",
    "tape = []  \n",
    "# - left variables that don't need gradient can be left out\n",
    "# - all intermediate variables must be included (unfortunately)\n",
    "# - order also matters (but not unique)\n",
    "# - final node also doesn't need to be in here\n",
    "\n",
    "### left variables\n",
    "\n",
    "X = Tensor(np.vstack([xs_f, ys_f]).T)\n",
    "Y = Tensor(zs_f.reshape(-1, 1))\n",
    "\n",
    "main_seed = jax.random.PRNGKey(42)\n",
    "seeds = jax.random.split(main_seed)\n",
    "\n",
    "W1, b1 = kaiming_init(2, 100, seeds[0])\n",
    "W2, b2 = kaiming_init(100, 100, seeds[1])\n",
    "W3, b3 = kaiming_init(100, 1, seeds[2])\n",
    "\n",
    "### intermediate variables\n",
    "\n",
    "transformed_X = X\n",
    "\n",
    "for W, b in zip([W1, W2, W3], [b1, b2, b3]):\n",
    "    \n",
    "    XW = transformed_X @ W\n",
    "    XW_plus_b = XW + b\n",
    "    relu_XW_plus_b = relu(XW_plus_b)\n",
    "    \n",
    "    tape.extend([W, b, XW, XW_plus_b, relu_XW_plus_b])\n",
    "    \n",
    "    transformed_X = relu_XW_plus_b\n",
    "\n",
    "mse_loss = mse(transformed_X, Y)\n",
    "\n",
    "mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a4439ba-c434-4b05-98fb-02039abdabd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss.cotangent = np.array(1.)\n",
    "\n",
    "for tensor in tape[::-1]: \n",
    "    tensor.pullback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3de531cc-cf38-4581-8d20-e3189f133b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2_grad = W2.cotangent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942a93de-ef41-44d0-8890-334ee6558b22",
   "metadata": {},
   "source": [
    "### Compare against JAX's autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32b59460-bbfe-470d-a53c-a964a78ed95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_func(W1, b1, W2, b2, W3, b3, X, Y):\n",
    "    layer1_out = jax.nn.relu(X @ W1 + b1)\n",
    "    layer2_out = jax.nn.relu(layer1_out @ W2 + b2)\n",
    "    layer3_out = jax.nn.relu(layer2_out @ W3 + b3)\n",
    "    mse_loss = np.mean((layer3_out - Y) ** 2)\n",
    "    return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6aa52ce-e87c-4e45-a319-00fa45ba6585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.4287767, dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_func(W1.value, b1.value, W2.value, b2.value, W3.value, b3.value, X.value, Y.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff862329-cd03-43fe-a37d-5a61c5e49fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_func_grad = jax.grad(mlp_func, argnums=[0, 1, 2, 3, 4, 5])\n",
    "W2_grad_jax = mlp_func_grad(W1.value, b1.value, W2.value, b2.value, W3.value, b3.value, X.value, Y.value)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6eb5163-6a42-473f-9e77-ca112eda3078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(W2_grad, W2_grad_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019f46f-e6a8-4d43-bf4e-17d28163ca2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdadc21-20cb-4ac3-b42a-5dea95ee9d16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
