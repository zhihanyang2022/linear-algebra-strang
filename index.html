<html>

<p><strong>Below are my notes for <u>MIT 18.S096 Matrix Calculus For Machine Learning And Beyond</u>:</strong></p>

<ul>
	<li>Lecture 4 Part 1: Gradients and Inner Products in Other Vector Space [<a href="./matrix_calculus/4_1_gradient_and_inner_products_in_other_vector_spaces.pdf">PDF</a>]</li>
	<ul>
	<li>Riesz representation theorem</li>
	<li>Gradient of Frobenius norm of A with respect to A</li>
	<li>Gradient of x.T @ A @ y with respect to A</li>
	<li>Gradient of sum(A) with respect to A</li>
	</ul>
</ul>

<p>&nbsp;</p>

</html>